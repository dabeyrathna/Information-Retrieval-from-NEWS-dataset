{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "merged.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPo9IZAHUZlXlNuiUESAfHL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dabeyrathna/Project2/blob/master/merged.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36znKNmFhqVw",
        "colab_type": "code",
        "outputId": "f26ff4ca-6e7f-4e21-abad-25fd746ee534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzFC6sGmiGH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "root_path = 'gdrive/My Drive/fovea_one_class'\n",
        "#!pwd\n",
        "#!cd gdrive/My\\ Drive/maskrcnn\n",
        "os.chdir(root_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxIZWMIWiIEu",
        "colab_type": "code",
        "outputId": "95f31032-2516-4e2f-a2d2-21387d48b943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==1.6\n",
        "!pip install keras==2.1.5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/0f/fbd8bb92459c75db93040f80702ebe4ba83a52cdb6ad930654c31dc0b711/tensorflow-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (45.8MB)\n",
            "\u001b[K     |████████████████████████████████| 45.9MB 91kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6) (0.34.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6) (1.29.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6) (1.12.0)\n",
            "Collecting tensorboard<1.7.0,>=1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/67/a8c91665987d359211dcdca5c8b2a7c1e0876eb0702a4383c1e4ff76228d/tensorboard-1.6.0-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.6) (1.18.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.6) (46.4.0)\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow==1.6) (3.2.2)\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.7.0,>=1.6.0->tensorflow==1.6) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.7.0,>=1.6.0->tensorflow==1.6) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.7.0,>=1.6.0->tensorflow==1.6) (3.1.0)\n",
            "Building wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=8438e8f3e883365c348833a1df07b8584bd1ff7037888c4c29a43b5f79665e02\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "Installing collected packages: html5lib, bleach, tensorboard, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.5\n",
            "    Uninstalling bleach-3.1.5:\n",
            "      Successfully uninstalled bleach-3.1.5\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorboard-1.6.0 tensorflow-1.6.0\n",
            "Collecting keras==2.1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.18.4)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed keras-2.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K49FFEPliJwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "\n",
        "import food\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Path to Ballon trained weights\n",
        "# You can download this file from the Releases page\n",
        "# https://github.com/matterport/Mask_RCNN/releases\n",
        "FOOD_WEIGHTS_PATH = \"/path/to/mask_rcnn_balloon.h5\"  # TODO: update this path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEegxgN8iT1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = food.FoodConfig()\n",
        "FOOD_DIR = os.path.join(ROOT_DIR, \"fovea\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T0ZWrKoiboj",
        "colab_type": "code",
        "outputId": "09c4c10a-5f59-4115-c678-9d5a0919552c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "# Override the training configurations with a few\n",
        "# changes for inferencing.\n",
        "class InferenceConfig(config.__class__):\n",
        "    # Run detection on one image at a time\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.9\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           lesion\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                70\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLKlifbEid3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device to load the neural network on.\n",
        "# Useful if you're training a model on the same \n",
        "# machine, in which case use CPU and leave the\n",
        "# GPU for training.\n",
        "DEVICE = \"/cpu:1\"  # /cpu:0 or /gpu:0\n",
        "\n",
        "# Inspect the model in training or inference modes\n",
        "# values: 'inference' or 'training'\n",
        "# TODO: code for 'training' test mode not ready yet\n",
        "TEST_MODE = \"inference\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsyCMLQEigQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ax(rows=1, cols=1, size=16):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Adjust the size attribute to control how big to render images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc0ACp2Iih1K",
        "colab_type": "code",
        "outputId": "4b38e1b8-a84f-4a03-d64d-a1d6a5c6b5d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "# Load validation dataset\n",
        "dataset = food.FoodDataset()\n",
        "\n",
        "dataset.load_food(FOOD_DIR, \"val\")\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'name': 'polygon', 'all_points_x': [271, 264, 261, 261, 263, 270, 279, 284, 285, 285, 282, 278, 271], 'all_points_y': [370, 366, 358, 350, 346, 343, 346, 349, 356, 364, 367, 370, 370]}]\n",
            "[{'food': '3'}]\n",
            "[1]\n",
            "[{'name': 'polygon', 'all_points_x': [239, 242, 250, 261, 268, 273, 271, 266, 257, 243, 239, 239], 'all_points_y': [282, 272, 266, 263, 266, 278, 288, 298, 301, 295, 289, 282]}]\n",
            "[{'food': '3'}]\n",
            "[1]\n",
            "[{'name': 'polygon', 'all_points_x': [303, 298, 290, 286, 285, 285, 293, 301, 310, 316, 318, 319, 317, 311, 303], 'all_points_y': [286, 286, 283, 278, 268, 258, 251, 250, 253, 256, 263, 273, 281, 286, 286]}]\n",
            "[{'food': '3'}]\n",
            "[1]\n",
            "[{'name': 'polygon', 'all_points_x': [209, 202, 197, 195, 198, 203, 210, 217, 222, 226, 226, 222, 217, 209], 'all_points_y': [289, 288, 278, 265, 254, 248, 248, 248, 254, 266, 277, 283, 290, 289]}]\n",
            "[{'food': '3'}]\n",
            "[1]\n",
            "[{'name': 'polygon', 'all_points_x': [171, 164, 157, 155, 158, 168, 180, 190, 195, 196, 194, 186, 180, 171], 'all_points_y': [308, 305, 296, 283, 275, 270, 269, 273, 279, 287, 298, 304, 309, 308]}]\n",
            "[{'food': '3'}]\n",
            "[1]\n",
            "[{'name': 'polygon', 'all_points_x': [344, 339, 330, 320, 311, 302, 297, 298, 306, 316, 322, 333, 341, 346, 344], 'all_points_y': [326, 338, 346, 348, 346, 340, 330, 314, 303, 298, 297, 297, 302, 313, 326]}]\n",
            "[{'food': '3'}]\n",
            "[1]\n",
            "[{'name': 'polygon', 'all_points_x': [265, 258, 250, 244, 238, 236, 241, 244, 255, 266, 276, 282, 288, 290, 292, 290, 286, 277, 265], 'all_points_y': [287, 290, 287, 284, 276, 263, 253, 245, 241, 238, 240, 242, 249, 257, 266, 271, 281, 285, 287]}]\n",
            "[{'food': '3'}]\n",
            "[1]\n",
            "[{'name': 'polygon', 'all_points_x': [239, 230, 230, 236, 250, 259, 264, 262, 258, 250, 239], 'all_points_y': [117, 106, 92, 78, 77, 84, 98, 115, 121, 124, 117]}]\n",
            "[{'food': '3'}]\n",
            "[1]\n",
            "[{'name': 'polygon', 'all_points_x': [285, 281, 277, 277, 283, 294, 301, 310, 319, 323, 327, 327, 324, 316, 308, 300, 292, 288, 285], 'all_points_y': [271, 266, 258, 250, 239, 234, 231, 233, 239, 245, 254, 262, 270, 278, 280, 282, 280, 278, 271]}]\n",
            "[{'food': '3'}]\n",
            "[1]\n",
            "Images: 9\n",
            "Classes: ['BG', 'fovea']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKGcIJ61ivIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model in inference mode\n",
        "with tf.device(DEVICE):\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
        "                              config=config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLUFUOJBjMtP",
        "colab_type": "code",
        "outputId": "9b8a965b-3fc9-4185-8322-3e0ce5e3f093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Set path to balloon weights file\n",
        "\n",
        "# Download file from the Releases page and set its path\n",
        "# https://github.com/matterport/Mask_RCNN/releases\n",
        "weights_path = \"logs/lesion20200530T0305/mask_rcnn_lesion_0017.h5\"\n",
        "# Or, load the last model you trained\n",
        "#weights_path = model.find_last()\n",
        "\n",
        "# Load weights\n",
        "print(\"Loading weights \", weights_path)\n",
        "model.load_weights(weights_path, by_name=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights  logs/lesion20200530T0305/mask_rcnn_lesion_0017.h5\n",
            "Re-starting from epoch 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_RcD4BbjnNp",
        "colab_type": "code",
        "outputId": "b95e03b8-511e-4cca-e5f0-6fdd11a1f34e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "image_id = random.choice(dataset.image_ids)\n",
        "image_id_les = random.choice(dataset_les.image_ids)\n",
        "image_id = 1\n",
        "image_id_les = 1\n",
        "\n",
        "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
        "\n",
        "info = dataset.image_info[image_id]\n",
        "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
        "                                       dataset.image_reference(image_id)))\n",
        "\n",
        "\n",
        "image_les, image_meta_lesh, gt_class_id_les, gt_bbox_les, gt_mask_les =\\\n",
        "    modellib.load_image_gt(dataset_les, config_les, image_id_les, use_mini_mask=False)\n",
        "    \n",
        "info_les = dataset_les.image_info[image_id_les]\n",
        "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id_les, \n",
        "                                       dataset_les.image_reference(image_id_les)))\n",
        "\n",
        "\n",
        "results = model.detect([image], verbose=1)\n",
        "results_les = model_les.detect([image_les], verbose=1)\n",
        "# Display results\n",
        "ax = get_ax(1)\n",
        "r = results[0]\n",
        "#r_les = results_les[0]\n",
        "\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset.class_names, r['scores'], ax=ax,\n",
        "                            title=\"Predictions\")\n",
        "\n",
        "# visualize.display_instances(image_les, r_les['rois'], r_les['masks'], r_les['class_ids'], \n",
        "#                             dataset_les.class_names, r_les['scores'], ax=ax,\n",
        "#                             title=\"Predictions_les\")\n",
        "\n",
        "# log(\"gt_class_id\", gt_class_id)\n",
        "# log(\"gt_bbox\", gt_bbox)\n",
        "# log(\"gt_mask\", gt_mask)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "info['class_ids']= [1]\n",
            "image ID: food.ARG-212OD_LAB_SP_NS.jpg (1) /content/gdrive/My Drive/fovea_one_class/fovea/val/ARG-212OD_LAB_SP_NS.jpg\n",
            "info['class_ids']= [2]\n",
            "image ID: food.ARG-212OD_LAB_SP_NS.jpg (1) /content/gdrive/My Drive/fovea_one_class/fovea/val/ARG-212OD_LAB_SP_NS.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-11d6394810a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mresults_les\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_les\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_les\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Display results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/fovea_one_class/mrcnn/model.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, images, verbose)\u001b[0m\n\u001b[1;32m   2500\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"inference\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Create model in inference mode.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m         assert len(\n\u001b[0;32m-> 2502\u001b[0;31m             images) == self.config.BATCH_SIZE, \"len(images) must be equal to BATCH_SIZE\"\n\u001b[0m\u001b[1;32m   2503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: len(images) must be equal to BATCH_SIZE"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuuZQNaIkjgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}